# **Text-similarity**

Задача оценки семантического сходства (text-similarity) заключается в определении степени схожести двух предложений с точки зрения транслируемого смысла.

Семантический поиск направлен на повышение точности сопоставления текстовых единиц путем понимания содержания поискового запроса. В отличие от использования только лексических совпадений, семантический поиск также может находить синонимы и другие единицы, имеющие схожий контекст употребления, поскольку этот алгоритм основывается на эмбеддингах – векторных представлениях текстовых единиц. Термин "embedding", взятый из английской литературы, используется для описания процесса, когда модель оцифровывает смысл слов и записывает его в виде упорядоченного набора числовых значений – вектора.

Наиболее эффективным способом построения моделей естественного языка является обучение нейронных сетей на основе архитектуры «трансформер». В качестве примера можно привести [BERT](https://arxiv.org/abs/1810.04805) – модель. которая используется для определения сходства слов и предложений.

Более качественные результаты можно получить, оптимизируя BERT под конкретные задачи. К примеру, модель [SBERT](https://arxiv.org/pdf/1908.10084.pdf) обучена непосредственно для работы с задачами по определению схожести предложений на основе косинусной меры.

Как отмечают разработчики [модели](https://habr.com/ru/companies/sberdevices/articles/527576/), её “архитектура представляет собой [сиамскую нейронную сеть](https://en.wikipedia.org/wiki/Siamese_neural_network) с тремя входами для триплета  «anchor — positive — negative».  К каждому из входов применяется модуль BERT, который и будет выполнять роль NLU в этом эксперименте. Модуль содержит в себе [wordpiece-токенизатор](https://paperswithcode.com/method/wordpiece) для преобразования входных строк в BERT-совместимый формат (input_ids, input_mask, token_type_ids), а также саму обучаемую модель BERT для векторизации текста.”

В результате дообучения модели SBERT для задачи поиска переводных эквивалентов было получено множество вариантов [мультиязычных моделей](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads&search=multi).

В настоящий момент мы считаем, что подобные мультиязыковые модели могут значительно приблизить проект к решению изначальной задачи, потенциально обеспечивая более высокое качество поиска наиболее схожих единиц греческого и церковнославянского текста.

В репозитории представлен [код](https://github.com/Drozhzhinastya/GSPC/blob/main/scripts/text-similarity/GSPC_sbert.ipynb) для работы с нашим текстом, а также результаты работы с моделью sentence-transformers/all-MiniLM-L6-v2, которая на наш взгляд демонстрирует более высокое качество сведения текстов Триоди.

Эксперименты проводились как на уровне отдельных предложений, так и на уровне гимнов (минимальных единиц разметки текста, представленной в нашей csv - см.выше). Каждое уникальное предложение/гимн греческого текста сопоставлялось с каждым предложением церковнославянского текста. Результаты экспериментов представлены в [csv таблице](https://github.com/Drozhzhinastya/GSPC/tree/main/csv/sbert), где собраны топ-5 церковнославянских предложений, выделенных моделью как наиболее близкие соответствующему греческому элементу.

В дальнейшей перспективе предстоит разработать решение для оценки качества сведения текстов и улучшения результатов выравнивания с опорой на него.