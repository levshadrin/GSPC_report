# Text-similarity {#sec-about_txt_similarity}

Задача оценки семантического сходства – **text-similarity** – заключается в определении степени схожести двух предложений с точки зрения транслируемого смысла.

:::{.callout-note collapse="true" icon=false appearance=simple title='Подробнее про text-similarity'}
Семантический поиск направлен на повышение точности сопоставления текстовых единиц путем понимания содержания поискового запроса. 

В отличие от использования только лексических совпадений, семантический поиск также может находить синонимы и другие единицы, имеющие схожий контекст употребления, поскольку этот алгоритм основывается на эмбеддингах – векторных представлениях текстовых единиц. 

Термин *`embedding`*, вошедший в научный оборот из английской литературы, используется для описания метода, по которому модель оцифровывает смысл слов и представляет его в виде упорядоченного набора числовых значений – вектора.
:::

## BERT и трансформеры {#sec-about_bert}

Наиболее эффективным способом построения моделей естественного языка является обучение нейронных сетей на основе архитектуры «трансформер». В качестве примера можно привести [**BERT**](https://arxiv.org/abs/1810.04805) – модель, используемая для определения сходства слов и предложений.

Более качественные результаты можно получить, оптимизируя *BERT* под конкретные задачи. К примеру, модель [**SBERT**](https://arxiv.org/pdf/1908.10084.pdf) обучена непосредственно для работы с задачами по определению схожести предложений на основе косинусной меры.

Как отмечают разработчики [модели](https://habr.com/ru/companies/sberdevices/articles/527576/)
> её “архитектура представляет собой [сиамскую нейронную сеть](https://en.wikipedia.org/wiki/Siamese_neural_network) с тремя входами для триплета  «anchor — positive — negative».  К каждому из входов применяется модуль *BERT*, который и будет выполнять роль NLU в этом эксперименте. Модуль содержит в себе [wordpiece-токенизатор](https://paperswithcode.com/method/wordpiece) для преобразования входных строк в BERT-совместимый формат (`input_ids`, `input_mask`, `token_type_ids`), а также саму обучаемую модель *BERT* для векторизации текста.”

В результате дообучения модели *SBERT* для задачи поиска переводных эквивалентов было получено множество вариантов [мультиязычных моделей](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads&search=multi).

## В контексте проекта {#sec-project_transformers}

Эксперименты с транфсормерами и языковыми моделями проводились на заключительных проектных спринтах и показали наилучший – хотя и далекий от приемлемого – результат выравнивания текстов за весь период работы.

:::{.callout-note collapse="true" icon=false appearance=simple title='Подробнее об экспериментах и результатах'}
Эксперименты проводились как на уровне отдельных предложений, так и на уровне гимнов (минимальных единиц разметки текста). Каждое уникальное предложение/гимн греческого текста сопоставлялось с каждым предложением церковнославянского текста. 

Результаты экспериментов представлены в [csv таблице](https://github.com/Drozhzhinastya/GSPC/tree/main/csv/sbert), где собраны топ-5 церковнославянских предложений, выделенных моделью как наиболее близкие соответствующему греческому элементу.
:::

В репозитории представлен [код](https://github.com/Drozhzhinastya/GSPC/blob/main/scripts/text-similarity/GSPC_sbert.ipynb) для работы с нашим текстом, а также результаты работы с моделью *sentence-transformers/all-MiniLM-L6-v2*, которая на наш взгляд демонстрирует более высокое качество сведения текстов Триоди.

:::{.callout-tip icon=false appearance=simple title='Перспективность для дальнейшей разработки'}
В настоящий момент мы считаем, что подобные мультиязыковые модели могут значительно приблизить проект к решению изначальной задачи, потенциально обеспечив более высокое качество поиска наиболее схожих единиц греческого и церковнославянского текста.

В дальнейшей перспективе предстоит разработать решение для оценки качества сведения текстов и улучшения результатов выравнивания с опорой на него.
:::